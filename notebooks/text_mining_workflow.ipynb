{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for text analysis from PDF\n",
    "\n",
    "Formalizing the workflow from various projects into a workflow that can be applied to various texts, including longer form documents from PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/arielsaffer/pest-text-pipeline/blob/main/notebooks/text_mining_workflow.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "0. Set up the workspace\n",
    "1. Extract text from PDF to produce a corpus of \"documents\" (e.g., pages, paragraphs, sentences)\n",
    "2. Apply exploratory text analysis: Topic modeling (LDA) and \n",
    "3. ... keyword search (regex)\n",
    "4. Machine learning to select for topics about presence.\n",
    "5. Geoparsing to extract locations from presence records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on = \"Local\" # \"Local\" or \"Colab\"\n",
    "# Local assumes that you have cloned the full Github repository to your local machine\n",
    "# Colab assumes that you are running this notebook on Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import general libraries\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Set up workspace\n",
    "\n",
    "if run_on == \"Local\":\n",
    "    # Set up pytesseract\n",
    "    import os\n",
    "    import pytesseract\n",
    "    os.chdir(\"..\")\n",
    "    # This should be the path of the tesseract installation\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
    "    import text_analysis.data_functions as ta\n",
    "    \n",
    "elif run_on == \"Colab\":\n",
    "    # Setup Google Drive mount\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Install required programs and packages\n",
    "    !sudo apt install tesseract-ocr\n",
    "    !pip install pytesseract\n",
    "    !pip install pdf2image\n",
    "    !pip install tomotopy\n",
    "    !python -m spacy download en_core_web_md\n",
    "\n",
    "    # Import the data functions from the Github repository\n",
    "    !git clone https://github.com/arielsaffer/pest_text_pipeline.git\n",
    "    import pest_text_pipeline.text_analysis.data_functions as ta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the location of the PDF file to be processed\n",
    "# Either a local path, relative path (to the repository root), \n",
    "# or a Google Drive path (typically starts with \"/content/drive/My Drive/\")\n",
    "data_dir = r\"data\"\n",
    "pdf_path = f\"{data_dir}\\DowleyBook6.19.24.pdf\"\n",
    "# Provide the language of the text\n",
    "language = 'eng'\n",
    "# Determine how the document should be subdivided (\"page\", \"paragraph\", or \"sentence\")\n",
    "document_level = \"paragraph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract text from PDF to produce a corpus of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = ta.pdf_to_corpus(pdf_path=pdf_path, lang=language, document_level=document_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the result\n",
    "\n",
    "text_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because this is a scanned text, you may need to do some \n",
    "# additional cleaning.\n",
    "\n",
    "# For example, I noticed that \" | \" appears intead of \" I \" in the text\n",
    "\n",
    "text_corpus[\"text\"] = text_corpus[\"text\"].str.replace(\" | \", \" I \")\n",
    "\n",
    "# And \" O \" and \" OQ \" appear, probably where there were marks on the page\n",
    "\n",
    "text_corpus[\"text\"] = text_corpus[\"text\"].str.replace(\" OQ \", \"\")\n",
    "text_corpus[\"text\"] = text_corpus[\"text\"].str.replace(\" O \", \"\")\n",
    "text_corpus[\"text\"] = text_corpus[\"text\"].str.replace(\" QO \", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the text corpus to a CSV file\n",
    "\n",
    "text_corpus.to_csv(f\"{pdf_path[:-4]}_{document_level}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Apply exploratory text analysis: topic modeling (LDA), keyword search (regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_table = ta.text_to_topics(text_corpus, iterations=10, num_topics=20)\n",
    "# 10 iterations here just for texting, should be higher in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the topics\n",
    "topic_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords you are interested in using to search for relevant text\n",
    "\n",
    "hunger_keywords = [\"famine\", \"hunger\", \"hungry\", \"shortage\", \"starv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the keywords\n",
    "\n",
    "ta.keyword_search(text_data=text_corpus, keywords=hunger_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine learning to select for topics about presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I don't have labeled data, here I am just going to consider all posts with \n",
    "# \"disease report keywords\" as positives.\n",
    "# These are very imperfect! (e.g., \"report\", \"found\", and \"present\" have many common uses)\n",
    "# These could be refined, or more ideally, a small sample of posts should be labeled manually\n",
    "\n",
    "disease_report_keywords = [\"report\", \"found\",  \"suffer\",\n",
    "                           \"loss\", \"present\", \"disease\", \n",
    "                           ]\n",
    "\n",
    "# Define the metric that will be used for model selection\n",
    "# Options: \"accuracy\", \"precision\", \"recall\", \"fscore\"\n",
    "selection_metric = \"fscore\"\n",
    "\n",
    "# Create the training dataframe\n",
    "\n",
    "text_corpus = pd.read_csv(f\"{pdf_path[:-4]}_{document_level}.csv\")\n",
    "\n",
    "# Add a Label column\n",
    "\n",
    "text_corpus[\"Label\"] = 0\n",
    "\n",
    "# Set the label to 1 if any of the keywords are in the text\n",
    "\n",
    "positive_locs = ta.keyword_search(\n",
    "    text_data=text_corpus[\"Text\"], keywords=disease_report_keywords\n",
    "    ).index\n",
    "\n",
    "text_corpus.loc[positive_locs, \"Label\"] = 1\n",
    "\n",
    "# Take a stratified sample of 20% of the data as our \"labeled data\"\n",
    "\n",
    "labeled_data = text_corpus.groupby('Label', group_keys=False).apply(lambda x: x.sample(frac=0.2)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test several models for classification \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the models to test\n",
    "\n",
    "models = [\n",
    "    LinearSVC(),\n",
    "    LogisticRegression(),\n",
    "    ComplementNB(),\n",
    "    DecisionTreeClassifier()\n",
    "]\n",
    "\n",
    "# Define the vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=0.001, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_sd</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_sd</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_sd</th>\n",
       "      <th>fscore</th>\n",
       "      <th>fscore_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.926371</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>0.816093</td>\n",
       "      <td>0.075313</td>\n",
       "      <td>0.799078</td>\n",
       "      <td>0.077066</td>\n",
       "      <td>0.803565</td>\n",
       "      <td>0.054994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC()</td>\n",
       "      <td>0.911267</td>\n",
       "      <td>0.027993</td>\n",
       "      <td>0.916520</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.599697</td>\n",
       "      <td>0.093675</td>\n",
       "      <td>0.720664</td>\n",
       "      <td>0.082730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ComplementNB()</td>\n",
       "      <td>0.818916</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.530066</td>\n",
       "      <td>0.085706</td>\n",
       "      <td>0.579584</td>\n",
       "      <td>0.082907</td>\n",
       "      <td>0.549784</td>\n",
       "      <td>0.068503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.839996</td>\n",
       "      <td>0.039545</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.149353</td>\n",
       "      <td>0.192780</td>\n",
       "      <td>0.096581</td>\n",
       "      <td>0.309408</td>\n",
       "      <td>0.140848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  accuracy  accuracy_sd  precision  precision_sd  \\\n",
       "3  DecisionTreeClassifier()  0.926371     0.018472   0.816093      0.075313   \n",
       "0               LinearSVC()  0.911267     0.027993   0.916520      0.075365   \n",
       "1            ComplementNB()  0.818916     0.031248   0.530066      0.085706   \n",
       "2      LogisticRegression()  0.839996     0.039545   0.927500      0.149353   \n",
       "\n",
       "     recall  recall_sd    fscore  fscore_sd  \n",
       "3  0.799078   0.077066  0.803565   0.054994  \n",
       "0  0.599697   0.093675  0.720664   0.082730  \n",
       "1  0.579584   0.082907  0.549784   0.068503  \n",
       "2  0.192780   0.096581  0.309408   0.140848  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the models\n",
    "\n",
    "model_testing_df = ta.test_multiple_models(\n",
    "    X = labeled_data[\"Text\"], \n",
    "    y = labeled_data[\"Label\"], \n",
    "    models = models, \n",
    "    vectorizer = vectorizer, \n",
    "    k = 10, \n",
    "    random_state = 40\n",
    "    )\n",
    "\n",
    "# Look at the results\n",
    "\n",
    "model_testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the best model to the full text corpus\n",
    "\n",
    "best_model = model_testing_df.loc[model_testing_df[selection_metric].idxmax(), \"model\"]\n",
    "\n",
    "# Train the best model on the full labeled data\n",
    "\n",
    "best_model.fit(X = vectorizer.fit_transform(labeled_data[\"Text\"]), y = labeled_data[\"Label\"])\n",
    "\n",
    "# Predict the labels for the full text corpus\n",
    "\n",
    "text_corpus[\"Predicted_Label\"] = best_model.predict(vectorizer.transform(text_corpus[\"Text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Predicted_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE FARMERS GAZETTE  References to  THE FAMINE...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At home, the Gazette regularly reported the p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The frequent references to failures and diseas...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>References to Potato Diseases Prior to Late B...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>In the potato, the main diseases prior to the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>The Secretary read a number of letters, from ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8276</th>\n",
       "      <td>A letter was also read from Professor Johnsto...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8279</th>\n",
       "      <td>A communication was also read from the Lord L...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8281</th>\n",
       "      <td>Also from William Phibbs, Esc., Seafield, Slig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8284</th>\n",
       "      <td>These returns admitted the existence of the di...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1657 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label  \\\n",
       "0     THE FARMERS GAZETTE  References to  THE FAMINE...      0   \n",
       "3      At home, the Gazette regularly reported the p...      1   \n",
       "9     The frequent references to failures and diseas...      1   \n",
       "10     References to Potato Diseases Prior to Late B...      1   \n",
       "11     In the potato, the main diseases prior to the...      1   \n",
       "...                                                 ...    ...   \n",
       "8275   The Secretary read a number of letters, from ...      1   \n",
       "8276   A letter was also read from Professor Johnsto...      1   \n",
       "8279   A communication was also read from the Lord L...      1   \n",
       "8281  Also from William Phibbs, Esc., Seafield, Slig...      1   \n",
       "8284  These returns admitted the existence of the di...      1   \n",
       "\n",
       "      Predicted_Label  \n",
       "0                   1  \n",
       "3                   1  \n",
       "9                   1  \n",
       "10                  1  \n",
       "11                  1  \n",
       "...               ...  \n",
       "8275                1  \n",
       "8276                1  \n",
       "8279                1  \n",
       "8281                1  \n",
       "8284                1  \n",
       "\n",
       "[1657 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the positive results\n",
    "\n",
    "text_corpus.loc[text_corpus[\"Predicted_Label\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geoparsing to extract locations from presence records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
